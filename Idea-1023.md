## M³-Index: Modality-aware Metric-and-Connectivity Co-Designed Index

### 1. 相关方向回顾（基于公开文献检索）
#### A. 连接性增强类：RoarGraph 及亲属

RoarGraph 的核心思想是：OOD 查询（尤其是跨模态，比如用文本找图像）在底库向量空间里往往“很孤立”，而且它真正的近邻彼此之间也很疏远。这破坏了传统 HNSW/NSG 假设：局部邻域是密集且连通的。RoarGraph通过构建一个“投影二部图”（projected bipartite graph），让查询模态和目标模态之间出现更多高层跨簇桥，从而保证查询能更快抵达相关区域，而不是在局部稀疏区域里盲走。实验显示它能在 OOD 任务下把高召回延迟显著降下去（在 90% recall 下最高 3.56× 提速）。

问题：
- 它主要解决“可到达性”，不是“相似度质量”。边让你走过去了，但最终打分还是用原生距离度量。跨模态 embedding 的尺度不一致（scale mismatch）和语义偏移没有被修正，所以最后 Top-k 仍可能不是语义上最正确的邻居。
- 它需要额外的跨模态桥边（新增的边会放大search开销），尤其在高召回场景下，候选集必须放大，搜索半径也扩大，导致延迟仍然上升。这对在线服务尤其是高并发下的 tail latency 很痛。
- 增量更新困难：大量预先基于训练集查询添加的边，对于新增数据未必适用。如果持续有新底库向量插入，如何高效地为它们增添跨模态连边是挑战。

#### B. 空间对齐 / 映射类：跨模态对齐、统一空间、对比学习
另一条线是让不同模态的向量都落到（或映射到）同一个共享空间，通过 CLIP 风格对比学习、线性投影、多头注意力式融合等，把 text/image/audio 全部 embed 到一个公共度量空间，然后用一个统一的 L2 或余弦距离做检索。大量 vision-language 表征学习、对比式对齐、codebook式对齐、注意力式跨模态对齐、互信息最大化式对齐都在干这个事[Survey](https://arxiv.org/html/2411.17040v2);[MUST]()。

问题：
- 线性投影往往是全局的。现实是：不同模态的 embedding 分布并不只是线性可对齐，同时不同模态内部的尺度（范数分布、协方差结构）差异很大。结果是，某个模态可能主导distance，出现模态主导效应，召回偏科[Mind the Gap](https://arxiv.org/abs/2203.02053)。
    - 不同modality的top10 导出 -> 对比L2 distance
    - 文本vector x [vector x] -> image vector （验证的motivation）
- 统一空间往往是“平均意义上的正确”；这种映射转化在Index中，可能扭曲局部几何结构，破坏细粒度邻接关系，导致 recall 下降。-> 我们不能只做“一刀切的同一空间”。
- 模态尺度不匹配（scale mismatch）导致一方主导：如果不同模态嵌入的数值范围或分布形状差异较大，直接以统一空间距离进行检索时，可能出现一种模态的向量主导距离度量的情况

### 2, 要解决的痛点
- OOD 查询在目标模态中的最近邻是稀疏、分散、跨簇的。这要求索引具有“长跳能力”和“多入口能力”，不然你走不到它们。（RoarGraph 方向在解决这个问题。）
- 跨模态检索的打分本身是畸形的。简单的 L2 / cosine 距离在跨模态场景下没有校正范数、协方差等模态依赖项，导致排序不准确；而直接把模态投影到统一空间的线性对齐又会损坏真实最近邻关系。

我们要的是：
- 一个索引，它本身知道“跨模态=高风险尺度不一致”，并在候选打分阶段主动补偿；
- 同时，这个索引在图结构层面也要为 OOD 查询提供高效可达性，但用的是受控的、少量的结构扩展，而不是盲目加很多桥边。

### Motivation
我们把问题拆成两层，而不是像现有工作一样在单层里强行解决全部问题：

- Routing Layer：
    - 一个稀疏但“多入口 aware”的上层图，用少量跨模态锚点节点 (anchors) 连接不同模态的高密度簇。它只负责把查询快速带到多个可能相关的目标簇，不负责最终排序。这个层次结构借鉴 RoarGraph 的跨簇连通性思路，但我们会控制边预算，并让这些跨模态锚点是“代表性子空间的局部统计”，而不是任意节点，从而减少边数和冗余遍历。

- Rerank Layer：
    - 一旦路由层把查询带到若干候选簇，我们不直接用原生距离，也不把所有向量生硬投影到单一空间。我们做的是“模态条件 Mahalanobis 距离 + 局部对齐校正”：打分度量不再是全局固定，而是按“查询模态 × 所在候选簇的局部统计”动态调节。

我们把它叫作 局部模态互校准距离 (Locally Calibrated Cross-Modal Distance, LC-CMD)。


### Design
#### 路由层设计
解决痛点 A：OOD 查询走不到对的区域，或者需要大量桥边导致遍历爆炸。

我们提出一个两阶段路由策略，叫做 Multi-Entry Anchored Routing (MEAR)：

- 跨模态锚点 (Anchors)
    - 我们从每个模态的高密度簇中挑出若干“簇中心 + 跨模态对齐稳定”的代表点，称为 anchor。anchor 的选择可以通过检索 K-means center，从而避免RoarGraph这种依赖大量query离线查询的。类似 RoarGraph 的“二部图”精神，但我们只保留这些锚点之间的跨模态边，而不是在任意节点上泛滥加边。这极大压缩了额外边数，边数量增长接近 O(#anchors)，而不是 O(#all_nodes)。
        - 新的距离函数 对高层 新增边

- 多入口搜索 (Multi-entry Seeds)
    - 当我们拿到一个查询 q（比如文本），我们不会只用单个入口点启动图搜索。我们通过轻量级相似度检索（例如使用倒排簇中心表或 IVF-like coarse quantizer）在不同模态的 anchor 集合里各找出前 m 个种子，然后并行在图顶层发起 m 条 BFS-like 小范围爬山。
    - 好处是：
        - OOD 查询往往“离所有人都远”，所以单入口容易卡住。多入口可以在不同模态视角同时试探，从而提升初始可达性。RoarGraph有类似“引导到高层跨簇区域”的直觉，但我们把这个做成显式的多入口路由策略。
        - 搜索深度可以受控。我们不需要让每个入口都跑到很深，而是收集候选簇 ID，然后把这些簇交给重打分层的 LC-CMD 去做精细排序。
    - 问题(TODO)：
        - 多入口这里，控制相同recall下，RoarGraph vs. 新方法 (early stop的逻辑)
        - 提前validate recall

- 簇级候选，而不是节点级候选
    - 路由层输出的不是“这 500 个候选点”，而是“这 5 个候选簇 C1…C5”。我们只需在每个簇里抓一小撮 top-L 近邻点进入重打分层，而不需要沿图深追所有可能邻接，从而削减高召回下的 tail latency。


#### Rerank Layer
- 模态自归一化 + 跨模态校正 distance
- 作用于high layer；修改高层连通性；找到更精准的入口

- 为什么使用[Mahalanobis distance](https://en.wikipedia.org/wiki/Mahalanobis_distance)
    - 这是一种计算两个未知样本集的相似度的算法 (现有的线性方案可以视为子集)
    - Modality-Conditioned Extension： 考虑不同模态的数据的分布不同，像传统线性方法一样，会造成“模态主导”问题；因此，引入模态条件的 Mahalanobis 距离：$$D_{MC}(x_i, y_j) = \sqrt{(x_i - y_j)^T \Sigma^{-1}_{c(i), c(j)} (x_i - y_j)}$$ 其中：(1). $c(i)$ 表示样本 $i$ 的模态；(2). $\Sigma_{c(i), c(j)}$ 是与模态组合 $(c(i), c(j))$ 相关的协方差矩阵，可定义为：
        - **单模态条件（intra-modal）** 时：$\Sigma_{c(i)}$
        - **跨模态条件（cross-modal）** 时：可取 $\Sigma^{1/2}_{c(i)} \Sigma^{1/2}_{c(j)}$ 或通过联合建模获得的协方差矩阵
    - 上面的算法虽然能够拟合不同分布数据的关系，消除跨模态distance的问题；但是其计算量大（$O(d^3)$复杂度），协方差矩阵size大（存储成本$d^2$ * num_of_modality）

- 算法降级(X-回到了线)：ANNS计算的两个高维度向量的distance（L2/Cosine）；将高维向量拆分考虑的话：在每一个维度上，不同模态的向量分布相同/不同可以反应在每个维度的均值和方差上。 =》 等价于按维进行归一化，然后计算distance
    - 对模态 $m$，我们估计每一维的方差：$$\sigma_{m,k}^2 = \mathrm{Var}[x_k \mid \text{modality } m], \quad k = 1 \ldots d$$ 然后定义一个按维度缩放的 Mahalanobis-like 距离：$$D_m(q, x)^2 = \sum_{k=1}^{d} \frac{(q_k - x_k)^2}{\sigma_{m,k}^2 + \epsilon}$$ 工程层面它非常好：
        - **存储**：每个模态只存一个长度为 $d$ 的方差向量 $\sigma_m^2$，是 $O(d)$。
        - **计算**：距离是按维度缩放过的 L2，成本 $O(d)$，跟普通余弦/L2 同阶。
        - **训练 / 统计**：$\sigma_{m,k}^2$ 可以用在线 Welford-like 算法做 streaming variance，不会炸内存。
    - 跨模态检索时，比如文本查询 $q$ 检索图像向量 $x$。文本模态 $t$ 波动小，图像模态 $v$ 波动大，直接 L2 时，图像那边大幅度的高能维会主导距离。我们用下面的融合缩放来平衡它们：$$D_{t \rightarrow v}(q, x)^2 = \sum_{k=1}^{d} \frac{(q_k - x_k)^2}{\alpha \sigma_{t,k}^2 + (1 - \alpha)\sigma_{v,k}^2 + \epsilon}$$ $\alpha$ 可设成 0.5 固定，或视 query 模态动态调节。

- search的时候
    - 新的距离函数 对高层 新增边
        - 相同模态 退化L2 distance
        - 不同模态，将不同模态考虑进去


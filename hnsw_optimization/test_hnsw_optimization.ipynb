{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HNSWä¼˜åŒ–æµ‹è¯•\n",
        "\n",
        "æœ¬notebookç”¨äºæµ‹è¯•HNSWä¼˜åŒ–çš„ä¸¤ä¸ªä¸»è¦åŠŸèƒ½ï¼š\n",
        "1. é«˜å±‚æ¡¥è¾¹ï¼ˆHigh-layer Bridge Edgesï¼‰\n",
        "2. è‡ªé€‚åº”å¤šå…¥å£ç§å­ï¼ˆAdaptive Multi-entry Seedsï¼‰\n",
        "\n",
        "ä½¿ç”¨Text2Imageæ•°æ®é›†è¿›è¡Œæµ‹è¯•ï¼Œå¹¶ä¸åŸºçº¿HNSWè¿›è¡Œå¯¹æ¯”ã€‚\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\n"
          ]
        }
      ],
      "source": [
        "# å¯¼å…¥å¿…è¦çš„åº“\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/root/code/vectordbindexing')\n",
        "sys.path.append('/root/code/vectordbindexing/hnsw_optimization')\n",
        "\n",
        "import numpy as np\n",
        "import json\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from io_utils import read_fbin, read_ibin\n",
        "import faiss\n",
        "\n",
        "# å¯¼å…¥æˆ‘ä»¬çš„ä¼˜åŒ–æ¨¡å—\n",
        "from data_loader import DataLoader\n",
        "from gt_utils import GroundTruthComputer\n",
        "from hnsw_baseline import HNSWBaseline\n",
        "from bridge_builder import BridgeBuilder\n",
        "from multi_entry_search import MultiEntrySearch, AdaptiveMultiEntrySearch\n",
        "from hnsw_with_bridges import HNSWWithBridges  # æ–°å¢ï¼šé›†æˆç‰ˆ HNSW\n",
        "\n",
        "print(\"æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸï¼\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. æ•°æ®åŠ è½½\n",
        "\n",
        "åŠ è½½Text2Imageæ•°æ®é›†å’Œé¢„è®¡ç®—çš„ground truth\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "åŠ è½½æ•°æ®é›†...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æ•°æ®å‘é‡å½¢çŠ¶: (1000000, 200)\n",
            "æŸ¥è¯¢å‘é‡å½¢çŠ¶: (100000, 200)\n",
            "\n",
            "ä½¿ç”¨è®­ç»ƒæ•°æ®: (1000000, 200)\n",
            "ä½¿ç”¨æŸ¥è¯¢æ•°æ®: (100000, 200)\n",
            "åŠ è½½ FAISS ground truth ç»“æœ...\n",
            "Ground truth å½¢çŠ¶: (100000, 100)\n"
          ]
        }
      ],
      "source": [
        "# æ•°æ®è·¯å¾„\n",
        "file_path = \"/root/code/vectordbindexing/Text2Image/base.1M.fbin\"\n",
        "query_path = \"/root/code/vectordbindexing/Text2Image/query.public.100K.fbin\"\n",
        "faiss_top100_path = \"/root/code/vectordbindexing/faiss_top100_results.json\"\n",
        "faiss_stats_path = \"/root/code/vectordbindexing/faiss_effort_stats.json\"\n",
        "faiss_effort_perc = \"/root/code/vectordbindexing/faiss_effort_percentiles.json\"\n",
        "\n",
        "print(\"åŠ è½½æ•°æ®é›†...\")\n",
        "\n",
        "# è¯»å–æ•°æ®é›†\n",
        "data_vector = read_fbin(file_path)\n",
        "query_vector = read_fbin(query_path)\n",
        "\n",
        "print(f\"æ•°æ®å‘é‡å½¢çŠ¶: {data_vector.shape}\")\n",
        "print(f\"æŸ¥è¯¢å‘é‡å½¢çŠ¶: {query_vector.shape}\")\n",
        "\n",
        "# ä¸ºäº†æµ‹è¯•ï¼Œä½¿ç”¨è¾ƒå°çš„æ•°æ®é›†\n",
        "n_train = len(data_vector)  # è®­ç»ƒæ•°æ®\n",
        "n_query = len(query_vector)  # æŸ¥è¯¢æ•°æ®\n",
        "\n",
        "X = data_vector[:n_train]\n",
        "Q = query_vector[:n_query]\n",
        "\n",
        "print(f\"\\nä½¿ç”¨è®­ç»ƒæ•°æ®: {X.shape}\")\n",
        "print(f\"ä½¿ç”¨æŸ¥è¯¢æ•°æ®: {Q.shape}\")\n",
        "\n",
        "# åŠ è½½ FAISS ground truth ç»“æœ\n",
        "print(\"åŠ è½½ FAISS ground truth ç»“æœ...\")\n",
        "gt_computer_loader = GroundTruthComputer()\n",
        "gt_neighbors = gt_computer_loader.load_ground_truth_from_json(faiss_top100_path, n_queries=n_query, k=100)\n",
        "print(f\"Ground truth å½¢çŠ¶: {gt_neighbors.shape}\")\n",
        "\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.5. é›†æˆç‰ˆ HNSWï¼šè‡ªåŠ¨æ¡¥æ¥è¾¹ + å¤šå…¥å£æœç´¢\n",
        "\n",
        "ä½¿ç”¨æ–°çš„ `HNSWWithBridges` ç±»ï¼Œå°†æ¡¥æ¥è¾¹æ„å»ºå’Œå¤šå…¥å£æœç´¢ç›´æ¥é›†æˆåˆ° HNSW ä¸­ã€‚\n",
        "\n",
        "**å…³é”®ç‰¹æ€§**ï¼š\n",
        "- æ„å»ºæ—¶è‡ªåŠ¨æ·»åŠ æ¡¥æ¥è¾¹ï¼ˆåŸºäº2è·³å¯è¾¾æ€§æ£€æµ‹ï¼‰\n",
        "- æœç´¢æ—¶è‡ªåŠ¨ä½¿ç”¨å¤šå…¥å£ç‚¹\n",
        "- å•ä¸€æ¥å£ï¼Œæ— éœ€æ‰‹åŠ¨ç®¡ç†å¤šä¸ªç»„ä»¶\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "æ„å»ºé›†æˆç‰ˆ HNSWï¼ˆè‡ªåŠ¨æ·»åŠ æ¡¥æ¥è¾¹ + å¤šå…¥å£æœç´¢ï¼‰\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"æ„å»ºé›†æˆç‰ˆ HNSWï¼ˆè‡ªåŠ¨æ·»åŠ æ¡¥æ¥è¾¹ + å¤šå…¥å£æœç´¢ï¼‰\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# åˆ›å»ºé›†æˆç‰ˆ HNSW\n",
        "hnsw_integrated = HNSWWithBridges(\n",
        "    dimension=X.shape[1],\n",
        "    M=64,\n",
        "    ef_construction=200,\n",
        "    # æ¡¥æ¥è¾¹é…ç½®\n",
        "    enable_bridges=True,\n",
        "    bridge_sample_ratio=0.05,  # 5% é‡‡æ ·ï¼ˆ500Kæ•°æ®ç”¨è¾ƒå°æ¯”ä¾‹ï¼‰\n",
        "    max_hop_distance=2,         # æ£€æŸ¥2è·³å¯è¾¾æ€§\n",
        "    # å¤šå…¥å£æœç´¢é…ç½®\n",
        "    enable_multi_entry=True,\n",
        "    num_entry_points=4\n",
        ")\n",
        "\n",
        "# æ„å»ºç´¢å¼•ï¼ˆè‡ªåŠ¨æ·»åŠ æ¡¥æ¥è¾¹ï¼‰\n",
        "start_time = time.time()\n",
        "hnsw_integrated.build_index(X)\n",
        "integrated_build_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nâœ… æ„å»ºå®Œæˆï¼Œè€—æ—¶: {integrated_build_time:.2f}ç§’\")\n",
        "\n",
        "# ç»Ÿè®¡ä¿¡æ¯\n",
        "stats = hnsw_integrated.get_statistics()\n",
        "print(f\"\\nç»Ÿè®¡ä¿¡æ¯:\")\n",
        "print(f\"  æ€»èŠ‚ç‚¹æ•°: {stats['total_nodes']}\")\n",
        "print(f\"  æ¡¥æ¥è¾¹æ•°: {stats['total_bridges']} æ¡\")\n",
        "print(f\"  æ¡¥æ¥è¾¹å¯†åº¦: {stats['total_bridges']/stats['total_nodes']:.4f}\")\n",
        "print(f\"  é«˜å±‚èŠ‚ç‚¹åˆ†å¸ƒ:\")\n",
        "for layer in sorted(stats['high_layer_count'].keys(), reverse=True):\n",
        "    count = stats['high_layer_count'][layer]\n",
        "    print(f\"    Layer {layer}: {count} ä¸ªèŠ‚ç‚¹\")\n",
        "\n",
        "# æµ‹è¯•å•ä¸ªæŸ¥è¯¢\n",
        "print(\"\\næµ‹è¯•é›†æˆç‰ˆæœç´¢...\")\n",
        "test_query = Q[0]\n",
        "integrated_neighbors, integrated_cost = hnsw_integrated.search(\n",
        "    test_query, k=100, ef_search=200\n",
        ")\n",
        "\n",
        "print(f\"æœç´¢ç»“æœ: {len(integrated_neighbors)} ä¸ªé‚»å±…ï¼Œæˆæœ¬: {integrated_cost}\")\n",
        "print(f\"å‰10ä¸ªé‚»å±…: {integrated_neighbors[:10]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "æµ‹è¯•ä¸åŒçš„å…¥å£ç‚¹æ•°é‡ï¼ˆnum_entry_pointsï¼‰\n",
            "======================================================================\n",
            "æµ‹è¯•æŸ¥è¯¢æ•°: 100\n",
            "Ground truth è®¾ç½®å®Œæˆ: (100, 100)\n",
            "\n",
            "æµ‹è¯• num_entry_points=1...\n"
          ]
        }
      ],
      "source": [
        "print(\"æµ‹è¯•ä¸åŒçš„å…¥å£ç‚¹æ•°é‡ï¼ˆnum_entry_pointsï¼‰\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# ä½¿ç”¨å‰100ä¸ªæŸ¥è¯¢è¿›è¡Œæµ‹è¯•\n",
        "n_test_queries = min(100, len(Q))\n",
        "print(f\"æµ‹è¯•æŸ¥è¯¢æ•°: {n_test_queries}\")\n",
        "\n",
        "# å‡†å¤‡ ground truth - ä½¿ç”¨å·²åŠ è½½çš„ gt_neighbors\n",
        "gt_eval = GroundTruthComputer()\n",
        "gt_eval.gt_neighbors = gt_neighbors[:n_test_queries]  # å…³é”®ï¼šè®¾ç½® ground truth\n",
        "\n",
        "print(f\"Ground truth è®¾ç½®å®Œæˆ: {gt_eval.gt_neighbors.shape}\")\n",
        "\n",
        "# æµ‹è¯•ä¸åŒçš„å…¥å£ç‚¹æ•°é‡\n",
        "entry_point_values = [1, 2, 4, 8]  # æµ‹è¯•1, 2, 4, 8ä¸ªå…¥å£ç‚¹\n",
        "results_by_entry = {}\n",
        "\n",
        "for num_entries in entry_point_values:\n",
        "    print(f\"\\næµ‹è¯• num_entry_points={num_entries}...\")\n",
        "    \n",
        "    # åˆ›å»º HNSW\n",
        "    hnsw_test = HNSWWithBridges(\n",
        "        dimension=X.shape[1],\n",
        "        M=64,\n",
        "        ef_construction=200,\n",
        "        enable_bridges=True,\n",
        "        bridge_sample_ratio=0.05,\n",
        "        max_hop_distance=2,\n",
        "        enable_multi_entry=(num_entries > 1),  # num_entries=1æ—¶ç¦ç”¨å¤šå…¥å£\n",
        "        num_entry_points=num_entries\n",
        "    )\n",
        "    \n",
        "    # æ„å»ºç´¢å¼•\n",
        "    build_start = time.time()\n",
        "    hnsw_test.build_index(X)\n",
        "    build_time_test = time.time() - build_start\n",
        "    \n",
        "    # æ‰¹é‡æœç´¢\n",
        "    all_neighbors = []\n",
        "    search_times = []\n",
        "    \n",
        "    for j in range(n_test_queries):\n",
        "        if j % 25 == 0:\n",
        "            print(f\"  å¤„ç†æŸ¥è¯¢ {j+1}/{n_test_queries}...\")\n",
        "        \n",
        "        start = time.time()\n",
        "        neighbors, _ = hnsw_test.search(Q[j], k=100, ef_search=200)\n",
        "        search_times.append(time.time() - start)\n",
        "        all_neighbors.append(neighbors)\n",
        "    \n",
        "    all_neighbors = np.array(all_neighbors)\n",
        "    \n",
        "    # è®¡ç®— recallï¼ˆä½¿ç”¨ç›¸åŒçš„ ground truthï¼‰\n",
        "    recall_10 = gt_eval.compute_recall(all_neighbors, k_eval=10)\n",
        "    recall_100 = gt_eval.compute_recall(all_neighbors, k_eval=100)\n",
        "    avg_time = np.mean(search_times) * 1000\n",
        "    \n",
        "    results_by_entry[num_entries] = {\n",
        "        'recall_10': recall_10,\n",
        "        'recall_100': recall_100,\n",
        "        'avg_time_ms': avg_time,\n",
        "        'build_time': build_time_test,\n",
        "        'bridges': hnsw_test.get_statistics()['total_bridges']\n",
        "    }\n",
        "    \n",
        "    print(f\"  æ„å»ºæ—¶é—´: {build_time_test:.2f}s\")\n",
        "    print(f\"  Recall@10:  {recall_10:.4f}\")\n",
        "    print(f\"  Recall@100: {recall_100:.4f}\")\n",
        "    print(f\"  æŸ¥è¯¢æ—¶é—´: {avg_time:.3f}ms\")\n",
        "    print(f\"  æ¡¥æ¥è¾¹: {results_by_entry[num_entries]['bridges']} æ¡\")\n",
        "\n",
        "# æ˜¾ç¤ºå¯¹æ¯”ç»“æœ\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"ä¸åŒå…¥å£ç‚¹æ•°é‡çš„æ€§èƒ½å¯¹æ¯”\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"\\n{'å…¥å£ç‚¹æ•°':<10} {'Recall@10':<12} {'Recall@100':<12} {'æŸ¥è¯¢æ—¶é—´(ms)':<15} {'æ¡¥æ¥è¾¹':<10}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for num_entries in entry_point_values:\n",
        "    result = results_by_entry[num_entries]\n",
        "    print(f\"{num_entries:<10} {result['recall_10']:<12.4f} {result['recall_100']:<12.4f} {result['avg_time_ms']:<15.3f} {result['bridges']:<10}\")\n",
        "\n",
        "# åˆ†ææœ€ä½³é…ç½®\n",
        "best_entry = max(entry_point_values, key=lambda x: results_by_entry[x]['recall_10'])\n",
        "print(f\"\\nğŸ’¡ åˆ†æ:\")\n",
        "print(f\"  æœ€ä½³å…¥å£ç‚¹æ•°: {best_entry} (Recall@10={results_by_entry[best_entry]['recall_10']:.4f})\")\n",
        "\n",
        "print(f\"\\nâœ… å…¥å£ç‚¹æ•°é‡æµ‹è¯•å®Œæˆ\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}

#!/usr/bin/env python3
"""
ä¼˜åŒ–ç‰ˆ HNSWï¼šä½¿ç”¨C++æ ¸å¿ƒå®ç°çš„2å±‚å›¾ç»“æ„
"""

import numpy as np
from typing import Tuple, Optional, Dict
import logging
import time

# å¯¼å…¥C++æ ¸å¿ƒæ¨¡å—
import hnsw_core
HNSW_CORE_AVAILABLE = True

logger = logging.getLogger(__name__)


class HNSWWithBridgesOptimized:
    """
    ä¼˜åŒ–ç‰ˆ HNSWï¼šä½¿ç”¨C++æ ¸å¿ƒå®ç°çš„2å±‚å›¾ç»“æ„
    
    ç‰¹æ€§ï¼š
    1. C++æ ¸å¿ƒå®ç°ï¼ˆé«˜æ€§èƒ½ï¼‰
    2. 2å±‚å›¾ç»“æ„ï¼ˆLayer0å…¨éƒ¨èŠ‚ç‚¹ï¼ŒLayer1~3-6%èŠ‚ç‚¹ï¼Œç¬¦åˆæ ‡å‡†HNSWï¼‰
    3. å›ºå®šå‡ºåº¦ï¼ˆM0å’ŒM1=M0/2ï¼‰
    4. Layer1æœç´¢åˆ°ç¨³å®š
    5. Layer0å¤šå…¥å£å¹¶è¡Œæœç´¢
    6. è¿”å›avg_visited, mean_latency, recall@10
    """

    def __init__(self,
                 dimension: int,
                 M: int = 32,
                 ef_construction: int = 200,
                 max_elements: int = 1000000,
                 seed: int = 42,
                 # å¤šå…¥å£æœç´¢å‚æ•°
                 num_entry_points: int = 4):
        """
        åˆå§‹åŒ–ä¼˜åŒ–ç‰ˆ HNSW

        Args:
            dimension: å‘é‡ç»´åº¦
            M: HNSW è¿æ¥æ•°ï¼ˆç¬¬0å±‚å‡ºåº¦M0=Mï¼Œç¬¬1å±‚å‡ºåº¦M1=M/2ï¼‰
            ef_construction: æ„å»ºæ—¶æœç´¢å®½åº¦
            max_elements: æœ€å¤§å…ƒç´ æ•°
            seed: éšæœºç§å­
            num_entry_points: é»˜è®¤å…¥å£ç‚¹æ•°é‡ï¼ˆå¯åœ¨æœç´¢æ—¶è°ƒæ•´ï¼‰
        """
        if not HNSW_CORE_AVAILABLE:
            raise ImportError("hnsw_core C++ module is required but not available")
        
        self.dimension = dimension
        self.M = M
        self.M0 = M  # ç¬¬0å±‚å‡ºåº¦
        self.M1 = M // 2  # ç¬¬1å±‚å‡ºåº¦
        self.ef_construction = ef_construction
        self.max_elements = max_elements
        self.seed = seed

        # å¤šå…¥å£æœç´¢é…ç½®
        self.num_entry_points = num_entry_points

        # åˆå§‹åŒ– C++ æ ¸å¿ƒç´¢å¼•
        self.index = hnsw_core.HNSW(
            dimension=dimension,
            M0=self.M0,
            ef_construction=ef_construction,
            max_elements=max_elements,
            seed=seed
        )

        # å­˜å‚¨å‘é‡æ•°æ®ï¼ˆç”¨äºè®¡ç®—recallç­‰ï¼‰
        self.vectors: Optional[np.ndarray] = None
        self.vector_ids: Optional[np.ndarray] = None

        self.is_built = False

    def build_index(self, vectors: np.ndarray, ids: Optional[np.ndarray] = None, 
                    rebuild_graph_from: str = "", load_from_roargraph: str = ""):
        """
        æ„å»ºç´¢å¼•

        Args:
            vectors: å‘é‡æ•°æ® (N x D)
            ids: å‘é‡IDï¼ˆå¯é€‰ï¼Œå½“å‰ç‰ˆæœ¬ä½¿ç”¨0åˆ°N-1ï¼‰
            rebuild_graph_from: å›¾ç»“æ„æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œtxtæ ¼å¼ï¼‰
                - å¦‚æœä¸ºç©ºï¼šæ­£å¸¸æ„å»ºç´¢å¼•
                - å¦‚æœä¸ä¸ºç©ºï¼šä»txtæ–‡ä»¶åŠ è½½å›¾ç»“æ„
            load_from_roargraph: RoarGraph indexæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
                - å¦‚æœä¸ä¸ºç©ºï¼šä»RoarGraph indexæ–‡ä»¶åŠ è½½ç¬¬0å±‚
        """
        # ä¿å­˜å‘é‡æ•°æ®
        self.vectors = vectors.astype(np.float32)
        if ids is None:
            ids = np.arange(len(vectors))
        self.vector_ids = ids.astype(np.int32)

        layer0_loaded = False
        
        if load_from_roargraph:
            # ä»RoarGraph indexæ–‡ä»¶åŠ è½½ç¬¬0å±‚
            logger.info(f"ä»RoarGraphæ–‡ä»¶åŠ è½½ç¬¬0å±‚: {load_from_roargraph}")
            start_time = time.time()
            self.load_layer0_from_roargraph(load_from_roargraph)
            load_time = time.time() - start_time
            logger.info(f"ç¬¬0å±‚åŠ è½½å®Œæˆ: {load_time:.2f}ç§’")
            layer0_loaded = True
        elif rebuild_graph_from:
            # ä»txtæ–‡ä»¶åŠ è½½å›¾ç»“æ„
            logger.info(f"ä»txtæ–‡ä»¶åŠ è½½å›¾ç»“æ„: {rebuild_graph_from}")
            start_time = time.time()
            self.load_layer0(rebuild_graph_from)
            load_time = time.time() - start_time
            logger.info(f"å›¾ç»“æ„åŠ è½½å®Œæˆ: {load_time:.2f}ç§’")
            layer0_loaded = True

        if layer0_loaded:
            # ç¬¬0å±‚å·²åŠ è½½ï¼Œåªæ„å»ºç¬¬1å±‚
            logger.info("å¼€å§‹æ„å»ºç¬¬1å±‚...")
            start_time = time.time()
            self.index.build_layer1_only(self.vectors)
            build_time = time.time() - start_time
            logger.info(f"ç¬¬1å±‚æ„å»ºå®Œæˆ: {build_time:.2f}ç§’")
        else:
            # æ­£å¸¸æ„å»ºç´¢å¼•ï¼ˆç¬¬0å±‚å’Œç¬¬1å±‚ï¼‰
            logger.info(f"æ„å»ºä¼˜åŒ–ç‰ˆ HNSW ç´¢å¼•: {len(vectors)} ä¸ªå‘é‡")
            start_time = time.time()
            self.index.build(self.vectors)
            build_time = time.time() - start_time
            logger.info(f"ç´¢å¼•æ„å»ºå®Œæˆ: {build_time:.2f}ç§’")

        self.is_built = True
        self._print_statistics()


    def search(self,
               query: np.ndarray,
               k: int,
               ef_search: int = 200,
               num_entry_points: Optional[int] = None) -> Tuple[np.ndarray, Dict]:
        """
        æœç´¢ï¼ˆè¿”å›é‚»å±…å’Œç»Ÿè®¡ä¿¡æ¯ï¼‰

        Args:
            query: æŸ¥è¯¢å‘é‡ (D,)
            k: è¿”å›çš„é‚»å±…æ•°é‡
            ef_search: æœç´¢å®½åº¦
            num_entry_points: å…¥å£ç‚¹æ•°é‡ï¼ˆNone åˆ™ä½¿ç”¨é»˜è®¤å€¼ï¼‰

        Returns:
            (neighbors, stats)
            - neighbors: é‚»å±…IDæ•°ç»„
            - stats: ç»Ÿè®¡ä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«:
                - visited_count: è®¿é—®çš„èŠ‚ç‚¹æ•° (avg_visited)
                - latency_us: æœç´¢å»¶è¿Ÿï¼ˆå¾®ç§’ï¼‰(mean_latency)
                - layer1_visited: ç¬¬1å±‚è®¿é—®çš„èŠ‚ç‚¹æ•°
                - layer0_visited: ç¬¬0å±‚è®¿é—®çš„èŠ‚ç‚¹æ•°
        """
        if not self.is_built:
            raise ValueError("ç´¢å¼•æœªæ„å»º")

        # ä½¿ç”¨æä¾›çš„æˆ–é»˜è®¤çš„å…¥å£ç‚¹æ•°é‡
        n_entries = num_entry_points if num_entry_points is not None else self.num_entry_points

        # è°ƒç”¨C++æœç´¢
        result = self.index.search(
            query.astype(np.float32),
            k=k,
            ef_search=ef_search,
            num_entry_points=n_entries
        )

        # è¿”å›é‚»å±…å’Œç»Ÿè®¡ä¿¡æ¯
        neighbors = result['neighbors']
        stats = {
            'visited_count': result['visited_count'],
            'latency_us': result['latency_us'],
            'layer1_visited': result['layer1_visited'],
            'layer0_visited': result['layer0_visited'],
        }

        return neighbors, stats

    def batch_search(self,
                     queries: np.ndarray,
                     k: int,
                     ef_search: int = 200,
                     num_entry_points: Optional[int] = None) -> Tuple[np.ndarray, Dict]:
        """
        æ‰¹é‡æœç´¢

        Args:
            queries: æŸ¥è¯¢å‘é‡ (N x D)
            k: è¿”å›çš„é‚»å±…æ•°é‡
            ef_search: æœç´¢å®½åº¦
            num_entry_points: å…¥å£ç‚¹æ•°é‡

        Returns:
            (all_neighbors, aggregated_stats)
            - all_neighbors: æ‰€æœ‰æŸ¥è¯¢çš„é‚»å±… (N x k)
            - aggregated_stats: èšåˆç»Ÿè®¡ä¿¡æ¯
        """
        if not self.is_built:
            raise ValueError("ç´¢å¼•æœªæ„å»º")

        n_entries = num_entry_points if num_entry_points is not None else self.num_entry_points

        # è°ƒç”¨C++æ‰¹é‡æœç´¢
        results = self.index.batch_search(
            queries.astype(np.float32),
            k=k,
            ef_search=ef_search,
            num_entry_points=n_entries
        )

        # æ”¶é›†æ‰€æœ‰é‚»å±…
        all_neighbors = np.array([r['neighbors'] for r in results])

        # èšåˆç»Ÿè®¡ä¿¡æ¯
        visited_counts = [r['visited_count'] for r in results]
        latencies = [r['latency_us'] for r in results]
        layer1_visited = [r['layer1_visited'] for r in results]
        layer0_visited = [r['layer0_visited'] for r in results]

        aggregated_stats = {
            'avg_visited': np.mean(visited_counts),
            'std_visited': np.std(visited_counts),
            'mean_latency': np.mean(latencies),
            'std_latency': np.std(latencies),
            'avg_layer1_visited': np.mean(layer1_visited),
            'avg_layer0_visited': np.mean(layer0_visited),
            'all_visited_counts': visited_counts,
            'all_latencies': latencies,
        }

        return all_neighbors, aggregated_stats

    def compute_recall(self,
                       results: np.ndarray,
                       ground_truth: np.ndarray,
                       k: int = 10) -> float:
        """
        è®¡ç®—recall@k

        Args:
            results: æœç´¢ç»“æœ (k,) æˆ– (N x k)
            ground_truth: ground truth (k,) æˆ– (N x k)
            k: è®¡ç®—recallçš„kå€¼

        Returns:
            recallå€¼
        """
        if results.ndim == 1:
            # å•ä¸ªæŸ¥è¯¢
            return hnsw_core.HNSW.compute_recall(results, ground_truth, k)
        else:
            # å¤šä¸ªæŸ¥è¯¢
            recalls = []
            for res, gt in zip(results, ground_truth):
                recall = hnsw_core.HNSW.compute_recall(res, gt, k)
                recalls.append(recall)
            return np.mean(recalls)

    def set_num_entry_points(self, num_entry_points: int):
        """
        åŠ¨æ€è°ƒæ•´å…¥å£ç‚¹æ•°é‡ï¼ˆæ— éœ€é‡å»ºç´¢å¼•ï¼‰

        Args:
            num_entry_points: æ–°çš„å…¥å£ç‚¹æ•°é‡
        """
        self.num_entry_points = num_entry_points
        logger.info(f"å…¥å£ç‚¹æ•°é‡å·²æ›´æ–°ä¸º: {num_entry_points}")

    def _print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        num_nodes = self.index.get_num_nodes()
        num_layer1 = self.index.get_num_layer1_nodes()
        
        logger.info("=" * 60)
        logger.info("ä¼˜åŒ–ç‰ˆ HNSW ç»Ÿè®¡:")
        logger.info(f"  æ€»èŠ‚ç‚¹æ•°: {num_nodes}")
        logger.info(f"  ç»´åº¦: {self.dimension}")
        logger.info(f"  M0 (ç¬¬0å±‚å‡ºåº¦): {self.M0}")
        logger.info(f"  M1 (ç¬¬1å±‚å‡ºåº¦): {self.M1}")
        logger.info(f"  ef_construction: {self.ef_construction}")
        logger.info(f"  ç¬¬1å±‚èŠ‚ç‚¹æ•°: {num_layer1} ({100*num_layer1/num_nodes:.1f}%)")
        logger.info(f"  ç†è®ºç¬¬1å±‚æ¯”ä¾‹: ~{100/self.M0:.1f}% (P(L>=1)=1/M0)")
        logger.info(f"  é»˜è®¤å…¥å£ç‚¹æ•°: {self.num_entry_points}")
        logger.info(f"  å®ç°æ–¹å¼: C++æ ¸å¿ƒ")
        logger.info("=" * 60)

    def get_statistics(self) -> dict:
        """è·å–è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯"""
        num_nodes = self.index.get_num_nodes()
        num_layer1 = self.index.get_num_layer1_nodes()

        return {
            'total_nodes': num_nodes,
            'dimension': self.dimension,
            'M0': self.M0,
            'M1': self.M1,
            'ef_construction': self.ef_construction,
            'layer1_nodes': num_layer1,
            'layer1_ratio': num_layer1 / num_nodes if num_nodes > 0 else 0,
            'num_entry_points': self.num_entry_points,
            'implementation': 'C++',
        }

    def save_layer0(self, filepath: str):
        """
        ä¿å­˜ç¬¬0å±‚å›¾ç»“æ„åˆ°æ–‡ä»¶

        æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªèŠ‚ç‚¹
        id \t vector \t neighbor1,neighbor2,...

        Args:
            filepath: ä¿å­˜è·¯å¾„
        """
        if not self.is_built:
            raise ValueError("ç´¢å¼•æœªæ„å»ºï¼Œæ— æ³•ä¿å­˜")

        logger.info(f"ä¿å­˜ç¬¬0å±‚å›¾ç»“æ„åˆ°: {filepath}")
        start_time = time.time()

        with open(filepath, 'w') as f:
            num_nodes = self.index.get_num_nodes()
            
            for node_id in range(num_nodes):
                # è·å–å‘é‡
                vector = self.vectors[node_id]
                
                # è·å–ç¬¬0å±‚é‚»å±…
                neighbors = self.index.get_layer0_neighbors(node_id)
                
                # æ ¼å¼åŒ–è¾“å‡º
                vector_str = ','.join(map(str, vector))
                neighbors_str = ','.join(map(str, neighbors))
                
                f.write(f"{node_id}\t{vector_str}\t{neighbors_str}\n")

        save_time = time.time() - start_time
        logger.info(f"ç¬¬0å±‚å›¾ç»“æ„ä¿å­˜å®Œæˆ: {save_time:.2f}ç§’")

    def load_layer0(self, filepath: str):
        """
        ä»æ–‡ä»¶åŠ è½½ç¬¬0å±‚å›¾ç»“æ„

        Args:
            filepath: æ–‡ä»¶è·¯å¾„
        """
        logger.info(f"åŠ è½½ç¬¬0å±‚å›¾ç»“æ„: {filepath}")
        start_time = time.time()

        # å‡†å¤‡æ•°æ®ç»“æ„
        node_vectors = []
        node_neighbors = []

        with open(filepath, 'r') as f:
            for line in f:
                parts = line.strip().split('\t')
                if len(parts) != 3:
                    continue
                
                node_id = int(parts[0])
                vector = np.array([float(x) for x in parts[1].split(',')])
                neighbors = [int(x) for x in parts[2].split(',') if x]
                
                node_vectors.append(vector)
                node_neighbors.append(neighbors)

        # è°ƒç”¨C++åŠ è½½æ–¹æ³•
        node_vectors_array = np.array(node_vectors, dtype=np.float32)
        self.index.load_layer0(node_vectors_array, node_neighbors)

        load_time = time.time() - start_time
        logger.info(f"ç¬¬0å±‚å›¾ç»“æ„åŠ è½½å®Œæˆ: {load_time:.2f}ç§’ï¼Œå…±{len(node_vectors)}ä¸ªèŠ‚ç‚¹")

    def load_layer0_from_roargraph(self, filepath: str):
        """
        ä»RoarGraph indexæ–‡ä»¶åŠ è½½ç¬¬0å±‚å›¾ç»“æ„
        
        æ³¨æ„ï¼šRoarGraph index åªå­˜å‚¨å›¾ç»“æ„ï¼ˆé‚»æ¥è¡¨ï¼‰ï¼Œä¸å­˜å‚¨å‘é‡æ•°æ®
        å‘é‡æ•°æ®å¿…é¡»é€šè¿‡ build_index() çš„ vectors å‚æ•°æä¾›
        
        Args:
            filepath: RoarGraph indexæ–‡ä»¶è·¯å¾„
        """
        import struct
        
        logger.info(f"ä»RoarGraphæ–‡ä»¶åŠ è½½ç¬¬0å±‚å›¾ç»“æ„: {filepath}")
        start_time = time.time()
        
        if self.vectors is None:
            raise ValueError("å¿…é¡»å…ˆé€šè¿‡ build_index() æä¾›å‘é‡æ•°æ®æ‰èƒ½åŠ è½½å›¾ç»“æ„")
        
        node_neighbors = []
        
        with open(filepath, 'rb') as f:
            # RoarGraph æ ¼å¼ï¼ˆåŸºäºå®é™…æ–‡ä»¶åˆ†æï¼‰:
            # - å­—èŠ‚ 0-3:  å…ƒæ•°æ®ï¼ˆè·³è¿‡ï¼‰
            # - å­—èŠ‚ 4-7:  èŠ‚ç‚¹æ€»æ•° âœ…
            # - å­—èŠ‚ 8å¼€å§‹: æ¯ä¸ªèŠ‚ç‚¹çš„é‚»å±…åˆ—è¡¨
            #   - 4å­—èŠ‚: é‚»å±…æ•°é‡
            #   - N*4å­—èŠ‚: Nä¸ªé‚»å±…ID
            
            # è¯»å–å¤´éƒ¨
            metadata = struct.unpack('I', f.read(4))[0]  # å­—èŠ‚0-3: å…ƒæ•°æ®ï¼ˆè·³è¿‡ï¼‰
            num_nodes_in_file = struct.unpack('I', f.read(4))[0]  # å­—èŠ‚4-7: èŠ‚ç‚¹æ€»æ•°
            
            logger.info(f"RoarGraphæ–‡ä»¶ä¿¡æ¯: èŠ‚ç‚¹æ•°={num_nodes_in_file:,}, å…ƒæ•°æ®={metadata:,}")
            
            if num_nodes_in_file != len(self.vectors):
                logger.warning(f"èŠ‚ç‚¹æ•°ä¸åŒ¹é…: æ–‡ä»¶ä¸­ {num_nodes_in_file}, å‘é‡æ•°æ® {len(self.vectors)}")
                # ä½¿ç”¨è¾ƒå°çš„å€¼
                num_nodes = min(num_nodes_in_file, len(self.vectors))
            else:
                num_nodes = num_nodes_in_file
            
            # è¯»å–æ¯ä¸ªèŠ‚ç‚¹çš„é‚»å±…åˆ—è¡¨
            logger.info(f"å¼€å§‹è¯»å– {num_nodes} ä¸ªèŠ‚ç‚¹çš„é‚»å±…åˆ—è¡¨...")
            invalid_neighbor_count = 0
            
            for node_id in range(num_nodes):
                # è¯»å–é‚»å±…æ•°é‡
                num_neighbors_bytes = f.read(4)
                if len(num_neighbors_bytes) < 4:
                    logger.warning(f"èŠ‚ç‚¹ {node_id} è¯»å–é‚»å±…æ•°é‡å¤±è´¥ï¼Œä½¿ç”¨ç©ºé‚»å±…åˆ—è¡¨")
                    node_neighbors.append([])
                    continue
                    
                num_neighbors = struct.unpack('I', num_neighbors_bytes)[0]
                
                # è¯»å–é‚»å±…IDåˆ—è¡¨
                if num_neighbors > 0:
                    neighbors_bytes = f.read(num_neighbors * 4)
                    if len(neighbors_bytes) < num_neighbors * 4:
                        logger.warning(f"èŠ‚ç‚¹ {node_id} é‚»å±…æ•°æ®ä¸å®Œæ•´")
                        neighbors = []
                    else:
                        raw_neighbors = list(struct.unpack(f'{num_neighbors}I', neighbors_bytes))
                        
                        # ğŸ”§ ä¿®å¤ï¼šè¿‡æ»¤æ‰è¶…å‡ºèŒƒå›´çš„é‚»å±…ID
                        neighbors = []
                        for nid in raw_neighbors:
                            if nid < num_nodes:
                                neighbors.append(nid)
                            else:
                                invalid_neighbor_count += 1
                else:
                    neighbors = []
                
                node_neighbors.append(neighbors)
                
                if (node_id + 1) % 100000 == 0:
                    logger.info(f"  è¿›åº¦: {node_id + 1}/{num_nodes}")
            
            if invalid_neighbor_count > 0:
                logger.warning(f"è¿‡æ»¤æ‰ {invalid_neighbor_count} ä¸ªè¶…å‡ºèŒƒå›´çš„é‚»å±…ID")
        
        # è°ƒç”¨C++åŠ è½½æ–¹æ³•ï¼ˆä½¿ç”¨å·²æœ‰çš„å‘é‡æ•°æ®ï¼‰
        logger.info(f"åŠ è½½å®Œæˆï¼Œå…± {len(node_neighbors)} ä¸ªèŠ‚ç‚¹çš„é‚»æ¥è¡¨")
        self.index.load_layer0(self.vectors, node_neighbors)
        
        load_time = time.time() - start_time
        logger.info(f"ç¬¬0å±‚ä»RoarGraphåŠ è½½å®Œæˆ: {load_time:.2f}ç§’")


if __name__ == "__main__":
    # æµ‹è¯•
    logging.basicConfig(level=logging.INFO)

    print("æµ‹è¯•ä¼˜åŒ–ç‰ˆ HNSW (C++æ ¸å¿ƒ)...")

    np.random.seed(42)
    X = np.random.randn(5000, 50).astype('float32')
    Q = np.random.randn(10, 50).astype('float32')

    # æ„å»ºç´¢å¼•ï¼ˆåªæ„å»ºä¸€æ¬¡ï¼‰
    hnsw = HNSWWithBridgesOptimized(
        dimension=50,
        M=16,
        ef_construction=100,
        num_entry_points=4
    )

    hnsw.build_index(X)

    # æµ‹è¯•ä¸åŒçš„å…¥å£ç‚¹æ•°é‡ï¼ˆæ— éœ€é‡å»ºï¼‰
    print("\næµ‹è¯•ä¸åŒçš„å…¥å£ç‚¹æ•°é‡:")
    print(f"{'num_entry':<12} {'avg_visited':<15} {'mean_latency(Î¼s)':<18} {'neighbors':<20}")
    print("-" * 70)
    
    for num_entry in [1, 2, 4, 8]:
        neighbors, stats = hnsw.search(
            Q[0], k=10, ef_search=50, num_entry_points=num_entry)
        print(f"{num_entry:<12} {stats['visited_count']:<15} "
              f"{stats['latency_us']:<18.2f} {len(neighbors):<20}")

    # æ‰¹é‡æœç´¢
    print("\næ‰¹é‡æœç´¢æµ‹è¯•:")
    all_neighbors, agg_stats = hnsw.batch_search(
        Q, k=10, ef_search=100, num_entry_points=4
    )
    
    print(f"  æŸ¥è¯¢æ•°: {len(Q)}")
    print(f"  avg_visited: {agg_stats['avg_visited']:.1f} Â± {agg_stats['std_visited']:.1f}")
    print(f"  mean_latency: {agg_stats['mean_latency']:.2f} Â± {agg_stats['std_latency']:.2f} Î¼s")
    print(f"  avg_layer1_visited: {agg_stats['avg_layer1_visited']:.1f}")
    print(f"  avg_layer0_visited: {agg_stats['avg_layer0_visited']:.1f}")

    print("\nâœ… æµ‹è¯•å®Œæˆï¼")
